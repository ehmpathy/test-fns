# vision: slow test reporter

## the outcome world

### before: the fog of slow tests

it's 3pm and the ci pipeline takes 12 minutes to run tests. you know _something_ is slow, but what?

```
npm run test:unit

 PASS  src/auth/login.test.ts (2.1s)
 PASS  src/invoice/invoice.test.ts (8.7s)
 PASS  src/customer/profile.test.ts (1.3s)
 ...47 more files...

Test Suites: 50 passed
Time:        73.421s
```

you squint at the output. invoice.test.ts took 8.7 seconds — that's suspicious. but which test _inside_ that file is slow? is it the setup? one specific test? a `given` block with expensive prep? you don't know. you can't know.

so you add `console.log(Date.now())` breadcrumbs, run it locally, grep the output, do mental math. an hour later you find the culprit: a single `useBeforeAll` that calls an unmocked api.

### after: the clarity of slowtest reporter

same scenario, different world:

```
npm run test:unit

 PASS  src/auth/login.test.ts (2.1s)
 PASS  src/invoice/invoice.test.ts (8.7s)
 PASS  src/customer/profile.test.ts (1.3s)
 ...47 more files...

Test Suites: 50 passed
Time:        73.421s

slowtest report:
+-----------------------------------------------------------------+----------+
| test                                                            | duration |
+-----------------------------------------------------------------+----------+
| src/invoice/invoice.test.ts                                     |   8.71s  |
|   given: [case1] overdue invoice with payment history           |   7.23s  |
|      when: [t0] nurture sequence triggered                      |   6.89s  |
|         then: it sends reminder email                           |   6.01s  |
+-----------------------------------------------------------------+----------+
| src/auth/login.test.ts                                          |   2.10s  |
|   given: [case3] user with mfa enabled                          |   1.82s  |
|      when: [t1] login with valid totp                           |   1.54s  |
+-----------------------------------------------------------------+----------+
| src/customer/profile.test.ts                                    |   1.30s  |
+-----------------------------------------------------------------+----------+

tip: 3 tests account for 82% of total runtime
```

the "aha" moment: you immediately see that `then: it sends reminder email` takes 6 seconds. the test name reveals it's probably a call to a real email service. you fix the mock and save 6 seconds per run — that's 30+ hours of developer wait time per year across the team.

### the shard unlock

even better: ci can now intelligently distribute work:

```yaml
# before: naive file-based shards
test:
  strategy:
    matrix:
      shard: [1, 2, 3, 4]
  steps:
    - run: npm test -- --shard=${{ matrix.shard }}/4
    # shard 1: 45s, shard 2: 12s, shard 3: 8s, shard 4: 9s
    # total wall time: 45s (blocked by slowest shard)

# after: time-aware shards via slowtest report
test:
  steps:
    - run: npm test -- --shard-by-time=.slowtest/times.json
    # shard 1: 18s, shard 2: 19s, shard 3: 18s, shard 4: 19s
    # total wall time: 19s (balanced load)
```

---

## user experience

### usecase 1: diagnose slow ci pipeline

**goal**: figure out why ci takes 12 minutes when it used to take 4

**contract**:
```ts
// jest.config.ts
import { slowtestReporter } from 'test-fns/slowtest';

export default {
  reporters: [
    'default',
    slowtestReporter({
      slow: 3000, // ms threshold
      output: '.slowtest/report.json',       // persist for trends
      top: 10,                               // show top 10 slowest
    }),
  ],
};
```

**output** (terminal):
```
slowtest report (10 slowest):

 #  file                              total    slowest block
 1  invoice/invoice.test.ts           8.71s    given: [case1] overdue invoice
 2  auth/login.test.ts                2.10s    given: [case3] mfa enabled
 3  customer/profile.test.ts          1.30s    then: updates avatar
 4  delivery/rate.test.ts             1.12s    when: [t2] international
 5  ...

1 file exceeds slow threshold (3s)
```

**output** (json for tools):
```json
{
  "generated": "2026-01-31T14:23:00Z",
  "summary": {
    "total": 73421,
    "files": 50,
    "slow": 1
  },
  "files": [
    {
      "path": "src/invoice/invoice.test.ts",
      "duration": 8710,
      "blocks": [
        {
          "type": "given",
          "name": "[case1] overdue invoice with payment history",
          "duration": 7230,
          "blocks": [
            {
              "type": "when",
              "name": "[t0] nurture sequence triggered",
              "duration": 6890,
              "tests": [
                { "name": "then: it sends reminder email", "duration": 6010 }
              ]
            }
          ]
        }
      ]
    }
  ]
}
```

### usecase 2: vitest integration

**goal**: same slow test visibility in vitest projects

**contract**:
```ts
// vitest.config.ts
import { slowtestReporter } from 'test-fns/slowtest';

export default defineConfig({
  test: {
    setupFiles: ['test-fns/vitest.setup'],
    reporters: [
      'default',
      slowtestReporter.vitest({
        slow: 3000,
        output: '.slowtest/report.json',
      }),
    ],
  },
});
```

identical output — same mental model regardless of test runner.

### usecase 3: enable time-based shards

**goal**: generate time manifest for ci shard tools

**contract**:
```ts
// jest.config.ts
import { slowtestReporter } from 'test-fns/slowtest';

export default {
  reporters: [
    'default',
    slowtestReporter({
      output: '.slowtest/times.json',
      format: 'shard', // simplified format for shard tools
    }),
  ],
};
```

**output** (shard format):
```json
{
  "version": 1,
  "files": {
    "src/invoice/invoice.test.ts": 8710,
    "src/auth/login.test.ts": 2100,
    "src/customer/profile.test.ts": 1300
  }
}
```

### usecase 4: track trends over time

**goal**: spot regressions before they compound

**contract**:
```ts
slowtestReporter({
  output: '.slowtest/report.json',
  baseline: '.slowtest/baseline.json', // compare against
})
```

**output**:
```
slowtest report:

  invoice/invoice.test.ts: 8.71s (+3.2s vs baseline)
  auth/login.test.ts: 2.10s (-0.5s vs baseline)

1 file regressed, 1 file improved
```

the reporter never fails the build — it's purely informational. if a test author wants to enforce speed budgets, they write an explicit assertion in their test.

---

## mental model

### how users describe it

> "it's like lighthouse for your test suite — it tells you what's slow and how to fix it"

> "we added the slow test reporter and immediately found 3 tests that call production apis by accident"

> "it's the absent piece for test time visibility"

### analogies

| concept | analogy |
|---------|---------|
| slowtest reporter | performance profiler for tests |
| threshold config | lighthouse performance budgets |
| json output | junit xml, but for time data |
| block-level time | flame graph for test hierarchy |

### terms: theirs vs ours

| user says | we call it |
|-----------|------------|
| "slow test finder" | `slowtestReporter` |
| "test time" | `duration` (ms) |
| "test blocks" | `blocks` (given/when hierarchy) |
| "shard data" | `format: 'shard'` output |

---

## evaluation

### how well does it solve the goals?

| goal | solution | quality |
|------|----------|---------|
| identify slow tests | hierarchical time report | strong |
| include given/when blocks | nested block time | strong |
| per-file time | file-level summary | strong |
| enable shards | json time manifest | strong |

### pros

- **zero behavior change**: pure observation, no test modification needed
- **works with current patterns**: understands `given`/`when`/`then` natively
- **cross-runner**: same api for jest and vitest
- **actionable output**: points directly at the slow code
- **machine-readable**: json output enables tool ecosystem

### cons

- **overhead**: time instrumentation adds small overhead (~1-5ms per block)
- **noise on fast tests**: sub-100ms tests may show variance
- **nested blocks require instrumentation**: raw `describe` won't have block-level time unless wrapped with `given`/`when`

### edgecases and pit of success

| edgecase | pit of success |
|----------|----------------|
| empty test file | gracefully report 0ms |
| concurrent tests | use per-test time, not wall clock |
| flaky time (gc, cpu spikes) | statistical average over multiple runs |
| absent baseline file | note in output; generate new baseline candidate |
| huge test suites (1000+ files) | stream output, paginate terminal report |
| nested `given` inside `given` | full hierarchy preserved in output |

### potential awkwardness

1. **vitest's different reporter api**: vitest reporters use a different interface than jest. we need to abstract this:
   ```ts
   // unified api hides the difference
   slowtestReporter()        // auto-detects runner
   slowtestReporter.jest()   // explicit jest
   slowtestReporter.vitest() // explicit vitest
   ```

2. **setup file time vs test time**: `useBeforeAll` runs in setup, not in individual tests. time data needs to attribute this correctly:
   ```
   given: [case1] with db seed     <- includes useBeforeAll time
     when: [t0] query executed
       then: returns results       <- excludes setup time
   ```

3. **parallel test execution**: jest and vitest can run tests in parallel. per-file time is wall clock, but per-test time needs to be isolated:
   ```json
   {
     "file": { "duration": 3000, "measure": "wall" },
     "tests": [
       { "name": "test a", "duration": 2000, "measure": "isolated" },
       { "name": "test b", "duration": 2500, "measure": "isolated" }
     ]
   }
   ```

4. **threshold ergonomics**: milliseconds are precise but hard to read. support human-friendly formats:
   ```ts
   slow: '3s'   // parsed to ms internally
   slow: 3000   // also valid
   ```

---

## summary

the slow test reporter transforms test performance from a black box into an observable system. developers can:

1. **see** which tests are slow (terminal report)
2. **diagnose** why they're slow (block-level time)
3. **track** regressions (baseline comparison)
4. **optimize** ci (shard manifest)

all via a single reporter that works identically across jest and vitest, understands `test-fns` bdd patterns natively, and produces both human-readable and machine-readable output.

slow tests, meet your diagnostic buddy.
